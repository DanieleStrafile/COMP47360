{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "import itertools\n",
    "from geopy.distance import vincenty\n",
    "from ipykernel import kernelapp as app\n",
    "%load_ext Cython\n",
    "import numba\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_hdf(\"cleaning_store.h5\", key=\"table_name\", where='Week_Day == 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Journey_Pattern_ID</th>\n",
       "      <th>Time_Frame</th>\n",
       "      <th>Vehicle_Journey_ID</th>\n",
       "      <th>Bus_Operator</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Delay_seconds</th>\n",
       "      <th>Block_ID</th>\n",
       "      <th>Vehicle_ID</th>\n",
       "      <th>Stop_ID</th>\n",
       "      <th>Week_Day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-11-12 06:00:04</td>\n",
       "      <td>00271003</td>\n",
       "      <td>2012-11-12</td>\n",
       "      <td>4846</td>\n",
       "      <td>RD</td>\n",
       "      <td>-6.398682</td>\n",
       "      <td>53.288082</td>\n",
       "      <td>8</td>\n",
       "      <td>27002</td>\n",
       "      <td>33319</td>\n",
       "      <td>2629</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-11-12 06:00:04</td>\n",
       "      <td>00151001</td>\n",
       "      <td>2012-11-12</td>\n",
       "      <td>5781</td>\n",
       "      <td>RD</td>\n",
       "      <td>-6.328866</td>\n",
       "      <td>53.271633</td>\n",
       "      <td>2</td>\n",
       "      <td>15001</td>\n",
       "      <td>33488</td>\n",
       "      <td>6282</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-11-12 06:00:04</td>\n",
       "      <td>046A0007</td>\n",
       "      <td>2012-11-12</td>\n",
       "      <td>7484</td>\n",
       "      <td>D1</td>\n",
       "      <td>-6.252283</td>\n",
       "      <td>53.341732</td>\n",
       "      <td>0</td>\n",
       "      <td>831238</td>\n",
       "      <td>33349</td>\n",
       "      <td>767</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-11-12 06:00:04</td>\n",
       "      <td>00070001</td>\n",
       "      <td>2012-11-12</td>\n",
       "      <td>6931</td>\n",
       "      <td>D1</td>\n",
       "      <td>-6.258450</td>\n",
       "      <td>53.357067</td>\n",
       "      <td>2</td>\n",
       "      <td>7017</td>\n",
       "      <td>43002</td>\n",
       "      <td>4962</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-11-12 06:00:06</td>\n",
       "      <td>039A1001</td>\n",
       "      <td>2012-11-12</td>\n",
       "      <td>3662</td>\n",
       "      <td>PO</td>\n",
       "      <td>-6.391812</td>\n",
       "      <td>53.394150</td>\n",
       "      <td>49</td>\n",
       "      <td>39003</td>\n",
       "      <td>36058</td>\n",
       "      <td>4747</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Timestamp Journey_Pattern_ID Time_Frame Vehicle_Journey_ID  \\\n",
       "0 2012-11-12 06:00:04           00271003 2012-11-12               4846   \n",
       "1 2012-11-12 06:00:04           00151001 2012-11-12               5781   \n",
       "2 2012-11-12 06:00:04           046A0007 2012-11-12               7484   \n",
       "3 2012-11-12 06:00:04           00070001 2012-11-12               6931   \n",
       "4 2012-11-12 06:00:06           039A1001 2012-11-12               3662   \n",
       "\n",
       "  Bus_Operator  Longitude   Latitude  Delay_seconds Block_ID Vehicle_ID  \\\n",
       "0           RD  -6.398682  53.288082              8    27002      33319   \n",
       "1           RD  -6.328866  53.271633              2    15001      33488   \n",
       "2           D1  -6.252283  53.341732              0   831238      33349   \n",
       "3           D1  -6.258450  53.357067              2     7017      43002   \n",
       "4           PO  -6.391812  53.394150             49    39003      36058   \n",
       "\n",
       "  Stop_ID  Week_Day  \n",
       "0    2629         0  \n",
       "1    6282         0  \n",
       "2     767         0  \n",
       "3    4962         0  \n",
       "4    4747         0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp             datetime64[ns]\n",
       "Journey_Pattern_ID            object\n",
       "Time_Frame            datetime64[ns]\n",
       "Vehicle_Journey_ID            object\n",
       "Bus_Operator                  object\n",
       "Longitude                    float64\n",
       "Latitude                     float64\n",
       "Delay_seconds                  int32\n",
       "Block_ID                      object\n",
       "Vehicle_ID                    object\n",
       "Stop_ID                       object\n",
       "Week_Day                       int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note About The Following Cell:\n",
    "This is the way we are sorting the data. First the Timeframe is the most important since it holds a unique Vehicle Journey ID (or it should) for every journey each day. \n",
    "Ideally we would then sort by VehicleJourneyId but the reality is that the data is messy. In order to avoid two buses at opposite sides of the city causing issues with the dataset we will now sort by the vehicle ID.\n",
    "Next the vehicle journey ID makes sense since we can then start to sort the entire dataset into individual journeys along a certain route.\n",
    "Lastly timestamp is obvious.\n",
    "\n",
    "We'll use this cell several times to keep the dataframe sorted and the index correct, as many of the loops in this notebook require this.\n",
    "\n",
    "You should deduce from this that there will be several cases of a VehicleJourneyId being repeated. cleaning up this is part of the challenge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Organise the Data\n",
    "#df.sort_values(['Time_Frame', 'Vehicle_ID', 'Vehicle_Journey_ID', 'Timestamp'], ascending=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove General Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" Remove every VehicleJourneyId which is equal to or below 5 rows in length. Realistically any journey (even the short ones)\n",
    "should be at least 5 rows of data in length, anything else is just noise. \"\"\"\n",
    "\n",
    "\n",
    "df = df.groupby(['Time_Frame', 'Vehicle_ID', 'Vehicle_Journey_ID'], as_index=False, group_keys=False).filter(lambda x: len(x) > 5)\n",
    "#df = pd.DataFrame(gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Organise the Data\n",
    "df.sort_values(['Time_Frame', 'Vehicle_ID', 'Vehicle_Journey_ID', 'Timestamp'], ascending=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Extra JourneyPatternId's From VehicleJourneyId's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create group object to work with \n",
    "gb = df.groupby(['Time_Frame', 'Vehicle_ID', 'Vehicle_Journey_ID'], as_index=False, group_keys=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@numba.jit\n",
    "def delete_outlier_journeypatternid(group):\n",
    "    \"\"\" Takes a pandas group object and iterates removing the least occuring JourneyPatterId in each.\n",
    "    If there are more than two or the occurances of the two are equal, it ignores it. \"\"\"\n",
    "    \n",
    "    grouped_values = group[\"Journey_Pattern_ID\"].value_counts()\n",
    "        \n",
    "    # If there's two Journey Pattern ID's\n",
    "    if len(grouped_values) == 2:\n",
    "                \n",
    "        # If the two journey pattern ID's occupy the same space then do nothing (likely it's a 'noise' journey)\n",
    "        if grouped_values[0] != grouped_values[1]:\n",
    "            \n",
    "            real_id = grouped_values.index.tolist()[0] \n",
    "            group = group[group.Journey_Pattern_ID == real_id]\n",
    "            \n",
    "    return group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Apply the mapping function to the dataset\n",
    "df = gb.apply(delete_outlier_journeypatternid)\n",
    "# 120 secs\n",
    "# to 79 seconds with jit numba\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create group object to work with \n",
    "gb = df.groupby(['Time_Frame', 'Vehicle_ID', 'Vehicle_Journey_ID'], as_index=False, group_keys=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Delete outliers (journey's with 3 id's and other noise inc. nulls)\n",
    "df = gb.filter(lambda x: len(x[\"Journey_Pattern_ID\"].unique()) == 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Vehicle Journey ID's With Two Occurances Each Day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These can either be...\n",
    "* Two buses completing the same route together with a stopover.\n",
    "* Incomplete journey's.\n",
    "* General noise in the data.\n",
    "\n",
    "In any case they occupy less than 1% of the data and change week to week, so they can be dropped without overall loss of data integrity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Filter out these outliers\n",
    "\n",
    "gb = df.groupby([\"Time_Frame\", \"Vehicle_Journey_ID\"], as_index=False, group_keys=False)\n",
    "\n",
    "df = gb.filter(lambda x: len(x[\"Vehicle_ID\"].unique()) == 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Up Start Of Journeys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Daniele\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Organise the Data\n",
    "df.sort_values(['Time_Frame', 'Vehicle_ID', 'Vehicle_Journey_ID', 'Timestamp'], ascending=True, inplace=True)\n",
    "\n",
    "# Clean up index\n",
    "df.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp             datetime64[ns]\n",
       "Journey_Pattern_ID            object\n",
       "Time_Frame            datetime64[ns]\n",
       "Vehicle_Journey_ID            object\n",
       "Bus_Operator                  object\n",
       "Longitude                    float64\n",
       "Latitude                     float64\n",
       "Delay_seconds                  int32\n",
       "Block_ID                      object\n",
       "Vehicle_ID                    object\n",
       "Stop_ID                       object\n",
       "Week_Day                       int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@numba.jit\n",
    "def GPS_clean(df):\n",
    "    \n",
    "    \"\"\" If the GPS coordinates remain the same for the first few rows of data, delete them. \"\"\"\n",
    "    \n",
    "    last_bus_id = df.loc[0, \"Vehicle_Journey_ID\"]\n",
    "    last_lat = df.loc[0, \"Latitude\"]\n",
    "    last_long = df.loc[0, \"Longitude\"]\n",
    "    new_start = True\n",
    "    \n",
    "    for row in itertools.islice(df.itertuples(),1,None):\n",
    "\n",
    "        # For every iteration\n",
    "        current_bus_id = row[4]\n",
    "        current_lat = row[7]\n",
    "        current_long = row[6]\n",
    "\n",
    "        # If it's a different vehicle journey id\n",
    "        if last_bus_id != current_bus_id:\n",
    "            last_bus_id = row[4]\n",
    "            last_lat = row[7]\n",
    "            last_long = row[6]\n",
    "            new_start = True\n",
    "            continue\n",
    "\n",
    "        # If it's the same journey\n",
    "        if new_start:\n",
    "            if current_lat == last_lat:\n",
    "                if current_long == last_long:\n",
    "                    # Flag\n",
    "                    df.set_value(row[0] - 1, \"Vehicle_Journey_ID\", 0)\n",
    "                    last_bus_id = row[4]\n",
    "                    last_lat = row[7]\n",
    "                    last_long = row[6]\n",
    "                    continue\n",
    "\n",
    "        # If it's the same journey but it's moved\n",
    "        if last_bus_id == current_bus_id:\n",
    "            if current_lat != last_lat or current_long != last_long:\n",
    "                new_start = False\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = GPS_clean(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#iterrows, original loop: 400 seconds\n",
    "#numba just in time compiler +  itertuples + skipping first row: 25 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Filter Out Rows Flagged\n",
    "df = df[df.Vehicle_Journey_ID != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Organise the Data\n",
    "df.sort_values(['Time_Frame', 'Vehicle_ID', 'Vehicle_Journey_ID', 'Timestamp'], ascending=True, inplace=True)\n",
    "# Clean up index\n",
    "df.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2484496, 12)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Distance Feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before dropping duplicate StopId's we must first measure the distance on each route. This requires that we use all rows of data.\n",
    "\n",
    "This will also make any VehicleJourneyId's which miss a stop along their journey useful data in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@numba.jit\n",
    "def get_distance(lat1, long1, lat2, long2):\n",
    "    \"\"\" Get distance between two geo coordinates \"\"\"\n",
    "    \n",
    "    stop1 = [lat1, long1]\n",
    "    stop2 = [lat2, long2]\n",
    "    \n",
    "    return vincenty(stop1, stop2).meters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp             datetime64[ns]\n",
       "Journey_Pattern_ID            object\n",
       "Time_Frame            datetime64[ns]\n",
       "Vehicle_Journey_ID            object\n",
       "Bus_Operator                  object\n",
       "Longitude                    float64\n",
       "Latitude                     float64\n",
       "Delay_seconds                  int32\n",
       "Block_ID                      object\n",
       "Vehicle_ID                    object\n",
       "Stop_ID                       object\n",
       "Week_Day                       int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@numba.jit\n",
    "def add_distance_todf(df):\n",
    "\n",
    "    # List to hold feature\n",
    "    df[\"Distance\"] = np.nan\n",
    "    \n",
    "    # Set up values on first iteration\n",
    "    last_id = df.loc[0, \"Vehicle_Journey_ID\"]\n",
    "    last_lat = df.loc[0, \"Latitude\"]\n",
    "    last_long = df.loc[0, \"Longitude\"]\n",
    "    last_distance = 0\n",
    "    \n",
    "    #set very first distance\n",
    "    df.set_value(0, \"Distance\", 0)\n",
    "\n",
    "    for row in itertools.islice(df.itertuples(),1,None):\n",
    "        \n",
    "        current_id = row[4]\n",
    "        current_lat = row[7]\n",
    "        current_long = row[6]\n",
    "        current_distance = get_distance(current_lat, current_long, last_lat, last_long)\n",
    "\n",
    "        # If it's a new Journey ID\n",
    "        if current_id != last_id:\n",
    "            last_lat = row[7]\n",
    "            last_long = row[6]\n",
    "            last_id = row[4]\n",
    "            last_distance = 0\n",
    "\n",
    "            df.set_value(row[0], \"Distance\", 0)\n",
    "            continue\n",
    "\n",
    "        # If it's not a new Journey ID\n",
    "        current_distance = get_distance(current_lat, current_long, last_lat, last_long)\n",
    "        \n",
    "        last_distance = last_distance + current_distance\n",
    "        \n",
    "        df.set_value(row[0], \"Distance\", last_distance)\n",
    "        last_lat = row[7]\n",
    "        last_long = row[6]\n",
    "        last_id = row[4]\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = add_distance_todf(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#original code: > 5 minutes, I stopped the loop and proceeded optimizing\n",
    "# jit numba + itertuples + skip first row: 246 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Stop ID Duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can filter the dataframe a little by removing dupicate stopID's. Although it would be better to train on every row it might be too much to compute. \n",
    "\n",
    "This will also help us later in making the database stop distances. There is not enough information to map the exact distance to each stop, so we will have to take some kind of average of the AtStop == 0 columns and subtract a little to get a rough distance to each stop in a Journey Pattern ID.\n",
    "\n",
    "Because this section keeps the first occurance of each StopId, this should be a very accurate way to estimate the distance to each stop on each route."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" This will delete all duplicates AFTER the first example of each is found. So when the bus arrives at the stop, \n",
    "all subsequent rows at that stop will be deleted. \"\"\"\n",
    "\n",
    "df.drop_duplicates([\"Time_Frame\", 'Vehicle_ID', \"Vehicle_Journey_ID\", \"Stop_ID\"],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Organise the Data\n",
    "df.sort_values([\"Time_Frame\", 'Vehicle_ID', \"Vehicle_Journey_ID\", 'Timestamp'], ascending=True, inplace=True)\n",
    "\n",
    "# Clean up index\n",
    "df.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check size of dataframe\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Time Taken Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@numba.jit\n",
    "def time_taken_feature(df):\n",
    "\n",
    "    # List to hold feature\n",
    "    df[\"TravelTime\"] = np.nan\n",
    "    \n",
    "    \n",
    "    # Set up values on first iteration\n",
    "    last_id = df.loc[0, \"Vehicle_Journey_ID\"]\n",
    "    start_time = df.loc[0, \"Timestamp\"]\n",
    "    \n",
    "    #set very first distance\n",
    "    df.set_value(0, \"TravelTime\", 0.0)\n",
    "\n",
    "    for row in itertools.islice(df.itertuples(),1,None):\n",
    "\n",
    "        current_time = row[1]\n",
    "        current_id = row[4]\n",
    "\n",
    "        # If it's a new Journey ID\n",
    "        if current_id != last_id:\n",
    "            last_id = row[4]        \n",
    "            start_time = row[1]        \n",
    "            df.set_value(row[0], \"TravelTime\", 0.0)\n",
    "            continue\n",
    "        \n",
    "        df.set_value(row[0], \"TravelTime\", abs((current_time - start_time).total_seconds()) )  \n",
    "        last_time = row[1]\n",
    "        last_id = row[4]\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = time_taken_feature(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Time Category Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[\"TimeCategory\"] = pd.DatetimeIndex(df['Timestamp']).round('30min')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Clean (added clean for Block ID's)\n",
    "## Section 1: Remove Extra Block ID's From VehicleJourneyId's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note df size for later\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check Issue of how many Journey's have two Block ID's\n",
    "\n",
    "@numba.jit\n",
    "def journeyID_two_blockID(df):\n",
    "\n",
    "    gb = df.groupby([\"Time_Frame\", 'Vehicle_ID', \"Vehicle_Journey_ID\"], as_index=False, group_keys=False)\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    for item in gb:\n",
    "\n",
    "        x = item[1][\"Block_ID\"].value_counts()\n",
    "\n",
    "        if len(x) > 1:\n",
    "            count += 1\n",
    "        \n",
    "    return df\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = journeyID_two_blockID(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2: If there's not a lot then delete them & Skip Section 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create group object to work with \n",
    "gb = df.groupby([\"Time_Frame\", 'Vehicle_ID', \"Vehicle_Journey_ID\"], as_index=False, group_keys=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Delete outliers (Block ID's with 3 id's and other noise inc. nulls)\n",
    "df = gb.filter(lambda x: len(x[\"Block_ID\"].unique()) == 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Now Delete All Journey's With 1 Row Of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create group object to work with \n",
    "gb = df.groupby([\"Time_Frame\", 'Vehicle_ID', \"Vehicle_Journey_ID\"], as_index=False, group_keys=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" Remove every VehicleJourneyId which is equal to or below 5 rows in length. Realistically any journey (even the short ones)\n",
    "should be at least 5 rows of data in length, anything else is just noise. \"\"\"\n",
    "\n",
    "\n",
    "gb = df.groupby([\"Time_Frame\", 'Vehicle_ID', \"Vehicle_Journey_ID\"], as_index=False, group_keys=False)\n",
    "\n",
    "df = gb.filter(lambda x: len(x) > 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['Time_hour'] = df['Timestamp'].values.astype('<M8[h]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "COLTYPES = {\n",
    "    \n",
    "    \"Time_hour\" : 'str',\n",
    "    \"Rain\" : 'float32',\n",
    "    \"Temp\" : 'float32',\n",
    "    \"Windspeed\" : 'float32'\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('WeatherData_cleaned.csv', dtype=COLTYPES, parse_dates=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.merge(df,df2, how='inner', on='Time_hour')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.drop('Time_hour', index=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hdf_path = 'cleaned_store.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_hdf(hdf_path, 'table_name', mode='a', format='table', append=True, data_columns=True,complevel=9, complib='blosc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
